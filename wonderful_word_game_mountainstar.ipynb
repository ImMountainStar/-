{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e730ddf",
   "metadata": {},
   "source": [
    "# 유사한 단어 찾기 게임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e831d92f",
   "metadata": {},
   "source": [
    "1. 사전학습된 모델 또는 적절한 데이터 셋을 찾는다. \n",
    "2. 워드 임베딩 모델을 학습 시킨다. \n",
    "3. 단어 유사도가 0.8 이상인 A,B를 랜덤 추출한다. \n",
    "4. A,B가 대응되는 C를 추출한다.\n",
    "5. D를 입력받는다. \n",
    "\n",
    "=> <br>\n",
    "A:B = C:D 관계에 대응하는 \n",
    "D를 찾는 게임 \n",
    "\n",
    "\n",
    "\n",
    "<출력 예시>\n",
    "\n",
    "관계 [수긍 : 추락 = 대사관 : ?] <br>\n",
    "모델이 예측한 가장 적합한 단어 : 잠입 <br>\n",
    "당신의 답변과 모델 예측의 유사도 : 0.34 <br>\n",
    "아쉽네요. 더 생각해보세요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53602ef5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "_________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87d101c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 데이터 set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0985a2d5",
   "metadata": {},
   "source": [
    "url : https://www.aihub.or.kr/aihubdata/data/view.do?pageIndex=5&currMenu=115&topMenu=100&srchOptnCnd=OPTNCND001&searchKeyword=&srchDetailCnd=DETAILCND001&srchOrder=ORDER001&srchPagePer=20&srchDataRealmCode=REALM002&aihubDataSe=data&dataSetSn=71304"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec24a04f",
   "metadata": {},
   "source": [
    "# 1. 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c26172c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "찾은 TSV 파일 수: 14622\n",
      " - data/TS_배움과 학문/Knowledge_배움과 학문_885.tsv\n",
      " - data/TS_배움과 학문/Knowledge_배움과 학문_891.tsv\n",
      " - data/TS_배움과 학문/Knowledge_배움과 학문_649.tsv\n",
      " - data/TS_배움과 학문/Knowledge_배움과 학문_661.tsv\n",
      " - data/TS_배움과 학문/Knowledge_배움과 학문_107.tsv\n",
      " - data/TS_배움과 학문/Knowledge_배움과 학문_113.tsv\n",
      " - data/TS_배움과 학문/Knowledge_배움과 학문_675.tsv\n",
      " - data/TS_배움과 학문/Knowledge_배움과 학문_1322.tsv\n",
      " - data/TS_배움과 학문/Knowledge_배움과 학문_846.tsv\n",
      " - data/TS_배움과 학문/Knowledge_배움과 학문_852.tsv\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불러오기 \n",
    "\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "base_dir = \"data\"  # 최상위 폴더\n",
    "\n",
    "# 하위 폴더까지 .tsv 전부 검색 (대소문자 대응)\n",
    "paths = glob.glob(os.path.join(base_dir, \"**\", \"*.tsv\"), recursive=True)\n",
    "paths += glob.glob(os.path.join(base_dir, \"**\", \"*.TSV\"), recursive=True)\n",
    "\n",
    "print(f\"찾은 TSV 파일 수: {len(paths)}\")\n",
    "for p in paths[:10]:\n",
    "    print(\" -\", p)\n",
    "if not paths:\n",
    "    raise FileNotFoundError(\"data 폴더(및 하위폴더)에 .tsv 파일을 못 찾았습니다. 경로/확장자 확인하세요.\")\n",
    "\n",
    "dfs = []\n",
    "for p in paths:\n",
    "    try:\n",
    "        df = pd.read_csv(p, sep=\"\\t\", encoding=\"utf-8\")  # 필요시 encoding 변경\n",
    "        # 출처 파일 표시(선택)\n",
    "        df[\"__source_file__\"] = os.path.relpath(p, base_dir)\n",
    "        dfs.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"[스킵] {p} -> {e}\")\n",
    "\n",
    "if not dfs:\n",
    "    raise ValueError(\"읽을 수 있는 TSV가 없습니다. 파일 인코딩/구분자/내용을 확인하세요.\")\n",
    "\n",
    "final_df = pd.concat(dfs, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9ef791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df[['utterance_id', 'text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e039f1e",
   "metadata": {},
   "source": [
    "# 2. 데이터 전처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c3a3545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29c24f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 파일\n",
    "ko_stopwords = pd.read_csv(\"ko_stopwords.txt\", header=None, names=[\"word\"])\n",
    "ko_stopwords = ko_stopwords[\"word\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "885f82ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추가 불용어 리스트\n",
    "extra_noise_nouns = {\n",
    "\n",
    "    \"리다\",\"이다\",\"하다\",\"인지\",\"이란\",\"이나\",\"가세\",\n",
    "    \"정말\",\"역시\",\"현재\",\"지난\",\"이후\",\"가지\",\"기간\",\"정도\",\n",
    "\n",
    "}\n",
    "\n",
    "okt = Okt()\n",
    "def clean_text_to_nouns(text: str):\n",
    "    # (a) NaN → 빈 리스트\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "\n",
    "    # 문자열 강제 변환\n",
    "    text = str(text)\n",
    "\n",
    "    # (b) 간단 정제\n",
    "    #  - 한글/영문/숫자/공백/기본 문장부호만 남기기\n",
    "    text = re.sub(r\"[^0-9a-zA-Z가-힣\\s\\.!?]\", \" \", text)\n",
    "    #  - 연속 공백 하나로 축소\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    # (c) 명사만 추출\n",
    "    nouns = okt.nouns(text) \n",
    "\n",
    "    # (d) 후처리 필터링\n",
    "    out = []\n",
    "    for t in nouns:\n",
    "        t = t.strip()\n",
    "        # 길이 1 이하 제거 (예: \"간\", \"인\" 등)\n",
    "        if len(t) <= 1:\n",
    "            continue\n",
    "        # 불용어/추가 잡음 제거\n",
    "        if t in ko_stopwords or t in extra_noise_nouns:\n",
    "            continue\n",
    "        out.append(t)\n",
    "\n",
    "    return out\n",
    "\n",
    "final_df[\"clean_nouns\"] = [clean_text_to_nouns(t) for t in final_df[\"text\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d689845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추가 불용어 집합\n",
    "extra_noise_nouns = {\n",
    "    \"리다\",\"이다\",\"하다\",\"인지\",\"이란\",\"이나\",\"가세\",\n",
    "    \"정말\",\"역시\",\"현재\",\"지난\",\"이후\",\"가지\",\"기간\",\"정도\",'이전','원래','사실','가장','건가','반면','대신','멍하니','누가','누가','대해','관련','는걸','서서','여러','통해'\n",
    "}\n",
    "\n",
    "def remove_extra_noise(nouns_list):\n",
    "\n",
    "    return [t for t in nouns_list if t not in extra_noise_nouns]\n",
    "\n",
    "\n",
    "final_df[\"clean_nouns\"] = [remove_extra_noise(n) for n in final_df[\"clean_nouns\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a98e46d",
   "metadata": {},
   "source": [
    "# 3. 데이터셋 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d10d3d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "sentences = final_df[\"clean_nouns\"].tolist()\n",
    "model = Word2Vec(\n",
    "    sentences=sentences,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    sg=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a76238",
   "metadata": {},
   "source": [
    "# 4. 게임 함수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aef8f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def make_A_B(sim = 0.8, max_trials =100):\n",
    "    for _ in range(max_trials):\n",
    "        A = random.choice(list(model.wv.key_to_index.keys()))\n",
    "        try: \n",
    "            sims_word = model.wv.most_similar(A, topn=200)\n",
    "            sims_list = [w for (w, s) in sims_word if s >= sim and w != A and w in model.wv.key_to_index]\n",
    "            #if not sims_list:       \n",
    "            #    continue\n",
    "            B = random.choice(sims_list)\n",
    "            return A, B\n",
    "        except KeyError: \n",
    "            continue\n",
    "    return None, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46fae2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_analogy( A, B, C, topn=1):\n",
    "    result = model.wv.most_similar(positive=[B, C], negative=[A], topn=topn)\n",
    "    return result[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "406704aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def play_game():\n",
    "    global cont\n",
    "    print(\"게임 시작!\\n\")\n",
    "\n",
    "    while True:  # 전체 게임 루프\n",
    "        A, B = make_A_B()\n",
    "        #words = list(model.wv.key_to_index.keys())\n",
    "        sims = model.wv.most_similar(A, topn=200)\n",
    "        cand_words = [w for (w, s) in sims if w not in {A, B}]  # 단어만 추출\n",
    "\n",
    "        C = None\n",
    "        predicted_D = None\n",
    "        score = None\n",
    "            \n",
    "        for w in cand_words[:5]:\n",
    "            pred, sc = get_analogy(A, B, w)\n",
    "            if pred in model.wv.key_to_index: \n",
    "                C, predicted_D, score = w, pred, sc\n",
    "                break\n",
    "\n",
    "            \n",
    "            predicted_D, score = get_analogy(A, B, C)\n",
    "            # 예측 단어도 vocab에 확실히 있는지 점검\n",
    "            if predicted_D in model.wv.key_to_index:\n",
    "                break\n",
    "\n",
    "        print(f'관계 [ {A} : {B} = {C} : ? ]')\n",
    "        while True: \n",
    "            answer_input = input(\"정답은? (정답확인 : 포기) : \").strip()\n",
    "\n",
    "            # 정답 공개\n",
    "            if answer_input == '포기':\n",
    "                print(f\"정답: {predicted_D} (score={score:.4f})\")\n",
    "                break\n",
    "\n",
    "            # vocab\n",
    "            if answer_input not in model.wv.key_to_index:\n",
    "                print(\"입력한 단어는 어휘에 없습니다. !!!!!!!retry!!!!!!!!\")\n",
    "                continue\n",
    "\n",
    "            # 유사도\n",
    "            similarity = model.wv.similarity(answer_input, predicted_D)\n",
    "            print(f\"입력값과 정답의 유사도: {similarity:.4f}\")\n",
    "\n",
    "            if answer_input == predicted_D:\n",
    "                print(\"정답입니다!\")\n",
    "                break\n",
    "            else:\n",
    "                print(\"땡!!!!!!!!!!!!!!! (정답 : 포기)\")\n",
    "\n",
    "\n",
    "        cont = input(\"\\n다음 문제 GO!!!!!!!!!!!!! (y/엔터=계속, n=종료): \").strip().lower()\n",
    "        if cont in {\"n\", \"no\"}:\n",
    "            print(\"게임 종료\")\n",
    "            break\n",
    "        #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62439457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "게임 시작!\n",
      "\n",
      "관계 [ 신진대사 : 전해질 = 촉진 : ? ]\n",
      "입력한 단어는 어휘에 없습니다. !!!!!!!retry!!!!!!!!\n",
      "입력한 단어는 어휘에 없습니다. !!!!!!!retry!!!!!!!!\n",
      "입력한 단어는 어휘에 없습니다. !!!!!!!retry!!!!!!!!\n",
      "입력한 단어는 어휘에 없습니다. !!!!!!!retry!!!!!!!!\n",
      "입력한 단어는 어휘에 없습니다. !!!!!!!retry!!!!!!!!\n",
      "입력값과 정답의 유사도: 0.7631\n",
      "땡!!!!!!!!!!!!!!! (정답 : 포기)\n",
      "입력값과 정답의 유사도: 0.2579\n",
      "땡!!!!!!!!!!!!!!! (정답 : 포기)\n",
      "입력한 단어는 어휘에 없습니다. !!!!!!!retry!!!!!!!!\n",
      "입력한 단어는 어휘에 없습니다. !!!!!!!retry!!!!!!!!\n",
      "입력값과 정답의 유사도: 0.7631\n",
      "땡!!!!!!!!!!!!!!! (정답 : 포기)\n",
      "입력값과 정답의 유사도: 0.7589\n",
      "땡!!!!!!!!!!!!!!! (정답 : 포기)\n",
      "입력값과 정답의 유사도: 0.2408\n",
      "땡!!!!!!!!!!!!!!! (정답 : 포기)\n",
      "정답: 위산 (score=0.8200)\n",
      "게임 종료\n",
      "====! 빠이염 !====\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    play_game()\n",
    "    if 'cont' in globals() and cont in {'n', 'no'}:\n",
    "        print('====! 빠이염 !====')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5523fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "npl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
